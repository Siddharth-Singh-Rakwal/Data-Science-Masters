{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e1cdd4-930d-4028-ba2b-a2e256489ea4",
   "metadata": {},
   "source": [
    "# Assignment | 7th April 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df3f92-3afd-43f9-b96d-45178e626092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df1257f4-ece6-41be-884e-6664e79cbaeb",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "Ans.\n",
    "\n",
    "Polynomial functions and kernel functions are both used in machine learning algorithms, but they serve different purposes.\n",
    "\n",
    "Polynomial functions are a class of mathematical functions that involve powers and coefficients of variables. In machine learning, polynomial functions can be used as basis functions to transform the original features of a dataset into a higher-dimensional feature space. This technique is known as polynomial feature expansion. By creating new features that are combinations of the original features raised to different powers, polynomial functions can capture nonlinear relationships between the features. Polynomial feature expansion is often used in linear regression models to fit curves to data that cannot be adequately represented by linear functions.\n",
    "\n",
    "On the other hand, kernel functions are used in various machine learning algorithms, particularly in kernel methods such as Support Vector Machines (SVMs). Kernel functions enable these algorithms to operate in a high-dimensional feature space without explicitly computing the transformed feature vectors. Kernel functions measure the similarity between pairs of data points in the original feature space or implicitly in the higher-dimensional feature space. They can efficiently calculate the dot product or inner product between feature vectors without explicitly transforming them. This avoids the computational burden associated with working in high-dimensional spaces.\n",
    "\n",
    "Polynomial kernel functions are a specific type of kernel function that allows kernel methods to capture polynomial relationships between the data points. The polynomial kernel function computes the dot product between two vectors as the sum of the products of their corresponding elements raised to a certain power. By adjusting the power parameter, the polynomial kernel can capture different degrees of polynomial relationships. The polynomial kernel enables SVMs and other kernel-based algorithms to learn nonlinear decision boundaries by implicitly operating in a higher-dimensional feature space.\n",
    "\n",
    "In summary, while polynomial functions are used for feature expansion and capturing nonlinear relationships, kernel functions, including polynomial kernel functions, enable machine learning algorithms to work efficiently in high-dimensional feature spaces and learn complex decision boundaries without explicitly transforming the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a26fd-fda9-4abc-b048-26c6c6241cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e93784c4-2e5c-4add-a7c7-ed00d3bf76e0",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "Ans.\n",
    "\n",
    "To implement an SVM with a polynomial kernel in Python using Scikit-learn, you can follow these steps:\n",
    "\n",
    "Step 1: Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be419a0-8478-4faf-b1f0-0268e5d48e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43de9e1-baa2-4ef6-af3f-7d48fbb6b898",
   "metadata": {},
   "source": [
    "Step 2: Generate or load your dataset. For demonstration purposes, let's generate a synthetic dataset using the make_classification function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f09eb50-076b-4ad7-984d-9430a8f9a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b77c3-9327-42ce-8c73-f73be1d6bc9c",
   "metadata": {},
   "source": [
    "Step 3: Split the dataset into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36e321a-693c-4e7b-b5c9-e601d45d65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ebb25b-0015-46d6-a2eb-f75a9a9cbc2f",
   "metadata": {},
   "source": [
    "Step 4: Create an instance of the SVC class and set the kernel parameter to 'poly' to specify the polynomial kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4037434-98a7-411f-92d9-1694f0c11cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='poly')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac53540-b324-40c8-9a03-9b996cc7aa27",
   "metadata": {},
   "source": [
    "Step 5: Fit the SVM model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6b34a9-f4b2-423c-8399-0de9b50d96d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84442a-5ddd-4fcf-beb3-b68d5cab3a2c",
   "metadata": {},
   "source": [
    "Step 6: Predict the labels for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3a17aa-28a1-4461-8df4-dc65329bb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d61d24-3d98-4cea-a6ee-38c83e697152",
   "metadata": {},
   "source": [
    "Step 7: Evaluate the accuracy of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c0d05a-0682-4c5d-bb68-5d7271a3cc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29867788-8daf-47ea-a054-73122e517ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1121f1e8-4705-473f-935f-e3345dc841bf",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "Ans.\n",
    "\n",
    "In Support Vector Regression (SVR), epsilon is a hyperparameter that controls the width of the margin around the regression line or hyperplane. It determines the acceptable deviation (or error) of the predicted values from the actual targets. The value of epsilon defines a tube around the regression line, and data points within this tube are not considered errors.\n",
    "\n",
    "Increasing the value of epsilon in SVR affects the number of support vectors. Support vectors are the data points that lie on the margin or within the tube defined by epsilon. As epsilon increases, the margin widens, allowing more data points to fall within the tube without being considered errors. Consequently, the number of support vectors tends to increase.\n",
    "\n",
    "When epsilon is small, the SVR model aims to fit the data more tightly, which leads to a narrower margin and fewer support vectors. In this case, the model is more sensitive to individual data points, and even small deviations are considered errors. On the other hand, when epsilon is large, the model allows more tolerance for errors and variations in the data, resulting in a wider margin and more support vectors.\n",
    "\n",
    "The selection of epsilon depends on the problem at hand and the desired trade-off between model complexity and generalization. A smaller epsilon may yield a more accurate but more complex model, while a larger epsilon may result in a simpler model with potentially less accuracy. It is often necessary to tune the value of epsilon along with other hyperparameters to find the optimal balance for a specific regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50bbad-5651-487b-9117-f5f89759f823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53e6d475-73d6-4cc2-bbf1-b0086a70d0d6",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "Ans.\n",
    "\n",
    "In Support Vector Regression (SVR), the choice of kernel function, C parameter, epsilon parameter, and gamma parameter can significantly affect the performance of the model. Let's discuss each parameter and its impact:\n",
    "\n",
    "1. Kernel function:\n",
    "The kernel function defines the similarity measure between data points in the feature space. It allows SVR to operate in a higher-dimensional space without explicitly computing the coordinates of the data points. Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.\n",
    "\n",
    "- Linear kernel: It represents a linear relationship between the input features and the target variable. It is useful when the data is expected to have a linear pattern.\n",
    "- Polynomial kernel: It captures non-linear relationships with polynomial terms of the input features. It is suitable when the data exhibits a polynomial relationship.\n",
    "- RBF kernel: It is a popular choice as it can capture complex non-linear relationships. It is effective when there are no assumptions about the data's underlying distribution.\n",
    "- Sigmoid kernel: It maps the data into a non-linear feature space using a sigmoid function. It can be useful when dealing with binary classification or when the data follows a sigmoidal pattern.\n",
    "\n",
    "The choice of the kernel function depends on the characteristics of the data and the expected relationships between features and the target variable. It may require experimentation and domain knowledge to select the appropriate kernel function.\n",
    "\n",
    "2. C parameter:\n",
    "The C parameter controls the trade-off between achieving a low training error and maintaining a wide margin. It determines the penalty for misclassifying data points and influences the complexity of the SVR model.\n",
    "\n",
    "- Small C: It allows for a wider margin and more tolerance for errors. This can lead to a simpler model with potentially higher bias and underfitting.\n",
    "- Large C: It enforces a stricter penalty for misclassifications, leading to a narrower margin and potentially more support vectors. This can result in a more complex model with higher variance and overfitting.\n",
    "\n",
    "Choosing the appropriate value for C depends on the desired balance between model complexity and generalization. If the training data is noisy or contains outliers, a larger C value might be necessary to reduce the effect of misclassified points.\n",
    "\n",
    "3. Epsilon parameter:\n",
    "The epsilon parameter determines the width of the margin around the regression line or hyperplane. It defines the acceptable deviation (or error) of the predicted values from the actual targets.\n",
    "\n",
    "- Small epsilon: It constrains the deviations tightly, aiming for a smaller margin. This can lead to a more accurate but potentially complex model.\n",
    "- Large epsilon: It allows for larger deviations, resulting in a wider margin. This can produce a simpler model but with potentially lower accuracy.\n",
    "\n",
    "The choice of epsilon depends on the specific problem and the acceptable level of deviation from the target values. If the task requires precise predictions, a smaller epsilon might be suitable. However, if the task allows for some margin of error, a larger epsilon can provide a more robust solution.\n",
    "\n",
    "4. Gamma parameter:\n",
    "The gamma parameter influences the shape of the decision boundary or regression function. It determines the reach of the individual training samples, affecting the flexibility of the model.\n",
    "\n",
    "- Small gamma: It leads to a broader influence of each training sample, resulting in a smoother decision boundary or regression function. This can prevent overfitting but may result in underfitting if the data has complex patterns.\n",
    "- Large gamma: It results in a narrow influence of each training sample, leading to a more localized and wiggly decision boundary or regression function. This can allow the model to capture intricate details in the data but can be prone to overfitting.\n",
    "\n",
    "The choice of gamma depends on the scale of the dataset and the complexity of the underlying relationships. If the dataset has many samples or the relationships are relatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5c535-794c-4beb-8d28-157ad42b874b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2661d0ce-9387-47c2-8833-3fffc0a14db7",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "- Import the necessary libraries and load the dataset.\n",
    "- Split the dataset into training and testing sets.\n",
    "- Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "- Create an instance of the SVC classifier and train it on the training data.\n",
    "- Use the trained classifier to predict the labels of the testing data.\n",
    "- Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,precision, recall, F1-score)\n",
    "- Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance.\n",
    "- Train the tuned classifier on the entire dataset\n",
    "- Save the trained classifier to a file for future use.\n",
    "\n",
    "Notes: You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples.\n",
    "\n",
    "Ans.\n",
    "\n",
    "Step 1: Import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663678af-6160-4ef8-89f6-d332cbc625af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d09d9c-8608-4586-95af-6d1a4a39f1ea",
   "metadata": {},
   "source": [
    "Step 2: Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7efcb85c-fb46-4e55-b961-7cb3f8451345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f0860-c755-4456-b428-b5e8950790cc",
   "metadata": {},
   "source": [
    "Step 3: Preprocess the data using any technique of your choice.\n",
    "For this example, we'll use standard scaling to normalize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65346043-5040-4df0-8b02-5a807ad8d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d84b73-1a93-40e5-86c0-ec8508603a8b",
   "metadata": {},
   "source": [
    "Step 4: Create an instance of the SVC classifier and train it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d29ddd8-b10d-47ef-982c-21be42ac9917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d216c8-618c-4e76-b764-7f29a6c79ec1",
   "metadata": {},
   "source": [
    "Step 5: Use the trained classifier to predict the labels of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fac6f02-cf4a-41f2-be37-e2fa430f3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387fa03-493e-4769-bde0-9225fb9a4b1f",
   "metadata": {},
   "source": [
    "Step 6: Evaluate the performance of the classifier using any metric of your choice.\n",
    "\n",
    "Let's use accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba989b4-301c-4d4b-a957-52caad9c9df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb9409-45e6-46e2-ab5b-f41cc9be18a8",
   "metadata": {},
   "source": [
    "Step 7: Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV.\n",
    "\n",
    "For simplicity, we'll use GridSearchCV to tune the hyperparameters of the SVC classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38b4e9a1-44b2-4b07-ab9e-6cf30eba446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba955453-c1fc-4845-aeac-d314b2076144",
   "metadata": {},
   "source": [
    "Step 8: Train the tuned classifier on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c122a7d-6a92-47c8-93d8-e664c87a6729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, kernel='linear')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc = grid_search.best_estimator_\n",
    "best_svc.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423ff6b-f52b-43c8-a252-78aecc9bd7f4",
   "metadata": {},
   "source": [
    "Step 9: Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dfc67c6-320c-47a8-a047-55b8b3bc68dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_classifier.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_svc, 'trained_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22cbf5-c4b5-4c70-99ac-7e62b2ac23f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
