{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca3d82c-45aa-4211-b876-c82350d7ff6c",
   "metadata": {},
   "source": [
    "# Assignment | 14th April 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20b756-2a73-4d5e-ba33-28576a6d4fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6a7fd1-3213-4a71-914a-d2331bb90bfc",
   "metadata": {},
   "source": [
    "Build a random forest classifier to predict the risk of heart disease based on a dataset of patient\n",
    "information. The dataset contains 303 instances with 14 features, including age, sex, chest pain type,\n",
    "resting blood pressure, serum cholesterol, and maximum heart rate achieved.\n",
    "\n",
    "Dataset link: https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?usp=share_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d0784-e696-4f34-861f-2aba0335a8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a1165b2-cf47-4117-9690-e1e437b7f140",
   "metadata": {},
   "source": [
    "Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the\n",
    "numerical features if necessary.\n",
    "\n",
    "Ans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198096-9bc8-4aa7-ae5a-1bf77fd7b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_url = \"https://drive.google.com/uc?export=download&id=1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ\"\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7351adb-f68d-4115-adf1-0ca7a069d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling/Checking missing values:\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values with the mean\n",
    "df.fillna(df.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6976633-e8e7-4b8f-80ec-d3506f19f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['chest_pain_type', 'sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc9f0f-e638-4918-9137-03f2270c437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical features:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select the numerical features to scale\n",
    "numerical_features = ['age', 'resting_blood_pressure', 'serum_cholesterol', 'maximum_heart_rate']\n",
    "\n",
    "# Perform standardization on the numerical features\n",
    "scaler = StandardScaler()\n",
    "df_encoded[numerical_features] = scaler.fit_transform(df_encoded[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488eac76-c045-471d-8750-f2b975ee567e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6319e7-946f-4a07-8de7-04cfa59241e5",
   "metadata": {},
   "source": [
    "Q2. Split the dataset into a training set (70%) and a test set (30%).\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee353920-e09b-426d-bba4-46f366a0a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df_encoded.drop('target', axis=1)  # Assuming 'target' is the column name for the target variable\n",
    "y = df_encoded['target']\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6750b93-1a37-4c81-a902-6e0bb76047cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4896cf4c-5588-4fea-aa1e-dbd3bd27a40c",
   "metadata": {},
   "source": [
    "Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each\n",
    "tree. Use the default values for other hyperparameters.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01cf46-ee0b-41ed-b8a0-9ba7f6d2343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99503245-7706-45b7-b7f4-8cbbf475a996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e074b1-c2aa-4afc-8c14-47a6f608809a",
   "metadata": {},
   "source": [
    "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2afa312-ccf4-4725-a152-14c5574750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f256e-590d-4677-85df-59da503b4a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ee93226-0892-4348-8d1d-ba822595d36a",
   "metadata": {},
   "source": [
    "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart\n",
    "disease risk. Visualise the feature importances using a bar chart.\n",
    "\n",
    "Ams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402379a8-7319-42de-98f8-c6e8921c10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Select the top 5 most important features\n",
    "top_features = feature_names[indices][:5]\n",
    "top_importances = importances[indices][:5]\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(5), top_importances, align='center')\n",
    "plt.xticks(range(5), top_features, rotation=45)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 5 Most Important Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e0c94-f9b7-4db4-b802-74435f132681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0470dfd5-0dba-4140-93e7-4bfd435a4f63",
   "metadata": {},
   "source": [
    "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try\n",
    "different values of the number of trees, maximum depth, minimum samples split, and minimum samples\n",
    "leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters.\n",
    "\n",
    "Ans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64b714-5370-4664-8224-a81b392b8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Create the random forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get the best model\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model using the test set\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d78702-df0b-4a41-968f-ec3ba9a91d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29df9878-5e56-4cc1-a781-95058bab1484",
   "metadata": {},
   "source": [
    "Q7. Report the best set of hyperparameters found by the search and the corresponding performance\n",
    "metrics. Compare the performance of the tuned model with the default model.\n",
    "\n",
    "Ans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bc917-dd28-4863-8b6a-63de13e6c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model using the test set\n",
    "y_pred_tuned = best_rf_classifier.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "\n",
    "# Evaluate the default model using the test set\n",
    "y_pred_default = rf_classifier.predict(X_test)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default)\n",
    "recall_default = recall_score(y_test, y_pred_default)\n",
    "f1_default = f1_score(y_test, y_pred_default)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Performance Metrics - Tuned Model:\")\n",
    "print(\"Accuracy:\", accuracy_tuned)\n",
    "print(\"Precision:\", precision_tuned)\n",
    "print(\"Recall:\", recall_tuned)\n",
    "print(\"F1 Score:\", f1_tuned)\n",
    "\n",
    "print(\"\\nPerformance Metrics - Default Model:\")\n",
    "print(\"Accuracy:\", accuracy_default)\n",
    "print(\"Precision:\", precision_default)\n",
    "print(\"Recall:\", recall_default)\n",
    "print(\"F1 Score:\", f1_default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e210fa-f396-4995-bacd-8f73f1feee4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e44a5200-f3cf-4839-bf3f-1771a43aab45",
   "metadata": {},
   "source": [
    "Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the\n",
    "decision boundaries on a scatter plot of two of the most important features. Discuss the insights and\n",
    "limitations of the model for predicting heart disease risk.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebc39f-12f3-48f7-bd4f-df0d2210120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensionality to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Select the two most important features for plotting\n",
    "feature1_idx = np.where(feature_names == top_features[0])[0][0]\n",
    "feature2_idx = np.where(feature_names == top_features[1])[0][0]\n",
    "feature1_values = X_pca[:, feature1_idx]\n",
    "feature2_values = X_pca[:, feature2_idx]\n",
    "\n",
    "# Plot the decision boundaries\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(feature1_values, feature2_values, c=y_train, cmap='coolwarm', alpha=0.8)\n",
    "plt.xlabel(top_features[0])\n",
    "plt.ylabel(top_features[1])\n",
    "plt.title('Decision Boundaries of Random Forest Classifier')\n",
    "plt.colorbar(label='Heart Disease')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c77349-c51f-4375-8beb-49ad787b784f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
