{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0561c63d-7831-440f-a755-fcb3646502e9",
   "metadata": {},
   "source": [
    "# Assignment | 9th April 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242983f-6ace-4209-9bc9-c5972afab3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce94957b-2916-4ff2-a5b3-10ebf03a680e",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Ans.\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics. It describes how to update the probability of a hypothesis based on new evidence or information. The theorem is named after the Reverend Thomas Bayes, an 18th-century British mathematician.\n",
    "\n",
    "Mathematically, Bayes' theorem can be stated as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "- P(A|B) represents the probability of hypothesis A being true given the evidence B.\n",
    "- P(B|A) is the probability of observing evidence B given that hypothesis A is true.\n",
    "- P(A) is the prior probability of hypothesis A being true before considering any evidence.\n",
    "- P(B) is the probability of observing evidence B.\n",
    "\n",
    "In simpler terms, Bayes' theorem allows us to calculate the probability of a hypothesis being true, given some observed evidence, by taking into account our prior knowledge and the likelihood of the evidence occurring under different hypotheses.\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, artificial intelligence, and data analysis. It forms the basis of Bayesian inference, which is a powerful framework for updating beliefs and making decisions in the presence of uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692af43-eb3d-4215-9a3e-c89dd028777b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feeba999-a699-4d8f-8987-9f1a41aabc9d",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Ans.\n",
    "\n",
    "Bayes' theorem can be stated as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "- P(A|B) represents the probability of hypothesis A being true given the evidence B.\n",
    "- P(B|A) is the probability of observing evidence B given that hypothesis A is true.\n",
    "- P(A) is the prior probability of hypothesis A being true before considering any evidence.\n",
    "- P(B) is the probability of observing evidence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978837dd-8a88-4e77-b852-bfeb35d24d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96884d83-550c-4a08-8fbe-3b7745c06653",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Ans.\n",
    "\n",
    "Bayes' theorem is used in various practical applications, particularly in fields where uncertainty and probability are involved. Here are a few examples of how Bayes' theorem is applied in practice:\n",
    "\n",
    "1. Medical diagnosis: Bayes' theorem is used in medical diagnosis to calculate the probability of a patient having a particular disease given certain symptoms or test results. By combining the prior probability of the disease, the sensitivity and specificity of diagnostic tests, and the observed symptoms or test results, Bayes' theorem helps update the probability of the disease.\n",
    "\n",
    "2. Spam filtering: Email spam filters often use Bayes' theorem to classify incoming emails as spam or legitimate. By considering the prior probability of certain words or phrases being associated with spam emails and updating the probabilities based on observed words in an email, Bayes' theorem enables the filter to make a probabilistic decision.\n",
    "\n",
    "3. Machine learning and data analysis: Bayes' theorem is a fundamental tool in Bayesian inference, which is a statistical framework for updating beliefs based on observed data. Bayesian models use Bayes' theorem to update prior probabilities to posterior probabilities, allowing for the estimation of unknown parameters or making predictions based on observed data.\n",
    "\n",
    "4. Weather forecasting: In weather forecasting, Bayes' theorem is used to update the probability of certain weather conditions based on observed data, historical patterns, and mathematical models. It helps meteorologists refine their predictions and improve the accuracy of weather forecasts.\n",
    "\n",
    "5. Fraud detection: Bayes' theorem is utilized in fraud detection systems to assess the probability of a transaction being fraudulent based on various factors such as transaction history, user behavior, and patterns of fraudulent activities. By updating the prior probability of fraud based on observed evidence, the system can flag suspicious transactions for further investigation.\n",
    "\n",
    "These are just a few examples of how Bayes' theorem is used in practice. Its applications extend to various domains where probability, inference, and decision-making under uncertainty are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69134039-9ca7-4129-9461-44e2a1423b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "938b7587-f8f6-4d73-b326-a4e2991a419c",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Ans.\n",
    "\n",
    "Bayes' theorem and conditional probability are closely related concepts in probability theory. In fact, Bayes' theorem can be derived from conditional probability.\n",
    "\n",
    "Conditional probability is the probability of an event A occurring given that another event B has already occurred. It is denoted as P(A|B), read as \"the probability of A given B.\" It is calculated as:\n",
    "\n",
    "P(A|B) = P(A ∩ B) / P(B)\n",
    "\n",
    "Here, P(A ∩ B) represents the probability of both events A and B occurring together, and P(B) is the probability of event B occurring.\n",
    "\n",
    "Bayes' theorem provides a way to reverse the conditional probability relationship. It allows us to calculate the probability of event B given event A by utilizing the conditional probability and incorporating prior knowledge. The formula for Bayes' theorem is as follows:\n",
    "\n",
    "P(B|A) = (P(A|B) * P(B)) / P(A)\n",
    "\n",
    "Here, P(B|A) represents the probability of event B occurring given that event A has occurred. P(A|B) is the conditional probability of event A given event B, P(B) is the prior probability of event B, and P(A) is the prior probability of event A.\n",
    "\n",
    "In summary, conditional probability is the foundation upon which Bayes' theorem is built. Bayes' theorem provides a framework to update our beliefs about the probability of an event based on observed evidence and prior knowledge. It allows us to reverse the conditional probability relationship and calculate the probability of an event given another event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72eebc4-09c0-41f0-a2f8-0b68132bb272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78618beb-7e34-4524-a0ca-05e0fe64f264",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Ans.\n",
    "\n",
    "When selecting a type of Naive Bayes classifier for a given problem, you typically consider the specific characteristics and requirements of the problem at hand. The choice of the Naive Bayes variant depends on the assumptions made about the independence of the features and the nature of the data. Here are some common types of Naive Bayes classifiers and their suitable use cases:\n",
    "\n",
    "1. Gaussian Naive Bayes:\n",
    "- Assumes that the continuous features follow a Gaussian (normal) distribution.\n",
    "- Suitable for continuous data where the features are assumed to have a bell-shaped distribution.\n",
    "\n",
    "2. Multinomial Naive Bayes:\n",
    "- Assumes that the features are multinomially distributed.\n",
    "- Typically used for discrete or count-based features, such as text data where the features represent word counts or term frequencies.\n",
    "\n",
    "3. Bernoulli Naive Bayes:\n",
    "- Assumes that the features are binary or follow a Bernoulli distribution.\n",
    "- Suitable for binary features or when you want to model presence/absence of features.\n",
    "\n",
    "4. Complement Naive Bayes:\n",
    "- Similar to Multinomial Naive Bayes but designed to address class imbalance problems.\n",
    "- Particularly useful when dealing with imbalanced datasets, where the majority class dominates the training data.\n",
    "\n",
    "The choice of the Naive Bayes variant depends on the nature of the data, the distribution of the features, and the specific requirements of the problem. It is important to consider the assumptions made by each variant and evaluate whether they hold true for your data. Additionally, you may also experiment with different variants and compare their performance using suitable evaluation metrics to determine the most appropriate choice for your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93477ba-a233-4404-aac1-683bff1658a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af194047-c0fb-45a9-b9fe-dc598b917a57",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "|-------|------|------|------|------|------|------|------|\n",
    "|   A   |   3  |   3  |   4  |   4  |   3  |   3  |   3  |\n",
    "|   B   |   2  |   2  |   1  |   2  |   2  |   2  |   3  |\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\n",
    "\n",
    "Ans.\n",
    "\n",
    "To predict the class of the new instance using Naive Bayes, we need to calculate the conditional probabilities for each class given the observed features.\n",
    "\n",
    "Given that the prior probabilities for classes A and B are assumed to be equal, we can calculate the posterior probabilities using Bayes' theorem. However, since we are only interested in comparing the probabilities and not the actual values, we can ignore the denominator of Bayes' theorem, as it is the same for both classes.\n",
    "\n",
    "Let's calculate the posterior probabilities for each class:\n",
    "\n",
    "For class A:\n",
    "P(A|X1=3, X2=4) = P(X1=3|A) * P(X2=4|A) * P(A)\n",
    "\n",
    "= (4/13) * (3/13) * (1/2)\n",
    "\n",
    "= 12/338\n",
    "\n",
    "For class B:\n",
    "P(B|X1=3, X2=4) = P(X1=3|B) * P(X2=4|B) * P(B)\n",
    "\n",
    "= (1/7) * (3/7) * (1/2)\n",
    "\n",
    "= 3/98\n",
    "\n",
    "Comparing the probabilities, we can see that P(A|X1=3, X2=4) > P(B|X1=3, X2=4). Therefore, Naive Bayes would predict that the new instance with features X1 = 3 and X2 = 4 belongs to class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa306b-ae77-4163-bc6f-df5a58180f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
